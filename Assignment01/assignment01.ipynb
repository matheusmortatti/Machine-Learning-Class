{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Code source adapted from: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_dataset(dataset):\n",
    "    vcut = {'Fair': 0, 'Good': 1, 'Very Good': 2, 'Premium': 3, 'Ideal': 4}\n",
    "    vcolor = {'D': 6, 'E': 5, 'F': 4, 'G': 3, 'H': 2, 'I': 1, 'J': 0}\n",
    "    vclarity = {'I1': 0, 'SI2': 1, 'SI1': 2, 'VS2': 3, 'VS1': 4, 'VVS2': 5, 'VVS1': 6, 'IF': 7}\n",
    "    \n",
    "    target = []\n",
    "    for row in dataset:\n",
    "        # Modify string to number values\n",
    "        row[\"cut\"] = vcut[row[\"cut\"]]\n",
    "        row[\"color\"] = vcolor[row[\"color\"]]\n",
    "        row[\"clarity\"] = vclarity[row[\"clarity\"]]\n",
    "        \n",
    "        # Normalize values\n",
    "        row[\"carat\"] = (float(row[\"carat\"]) - (0.2+5.01)/2)/(0.2+5.01)\n",
    "        row[\"cut\"] = (float(row[\"cut\"]) - (4/2))/4\n",
    "        row[\"color\"] = (float(row[\"color\"]) - (6/2))/6\n",
    "        row[\"clarity\"] = (float(row[\"clarity\"]) - (7/2))/7\n",
    "        row[\"x\"] = (float(row[\"x\"]) - (10.74/2))/10.74\n",
    "        row[\"y\"] = (float(row[\"y\"]) - (58.9/2))/58.9\n",
    "        row[\"z\"] = (float(row[\"z\"]) - (31.8/2))/31.8\n",
    "        row[\"depth\"] = (float(row[\"depth\"]) - (43+79)/2)/(43+79)\n",
    "        row[\"table\"] = (float(row[\"table\"]) - (43+95)/2)/(43+95)\n",
    "        \n",
    "        # Add X0 for ease of use\n",
    "        row[\"x0\"] = 1\n",
    "        \n",
    "        # Remove target element and insert into it's own list\n",
    "        target.append(float(row[\"price\"]))\n",
    "        del row[\"price\"]\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and treat training dataset\n",
    "dataset_train = []\n",
    "reader = csv.DictReader(open('diamonds-train.csv', 'r'))\n",
    "for line in reader:\n",
    "     dataset_train.append(line)\n",
    "\n",
    "target_train = treat_dataset(dataset_train)\n",
    "\n",
    "# Read and treat test dataset\n",
    "dataset_test = []\n",
    "reader = csv.DictReader(open('diamonds-test.csv', 'r'))\n",
    "for line in reader:\n",
    "     dataset_test.append(line)\n",
    "\n",
    "target_test = treat_dataset(dataset_test)\n",
    "\n",
    "# Auxilary vector for name to number mapping\n",
    "ds_index = [\"x0\", \"carat\", \"clarity\", \"color\", \"cut\", \"depth\", \"table\", \"x\", \"y\", \"z\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost_function(thetas, data, target):\n",
    "    m = len(data)\n",
    "    s = 0\n",
    "    for index in range(len(data)):\n",
    "        h = 0\n",
    "        for k,v in data[index].items():\n",
    "            h += thetas[k] * data[index][k]\n",
    "        s += (h - float(target[index]))*(h - float(target[index]))\n",
    "    return (1/(2*m)) * s\n",
    "\n",
    "def init_thetas(data):\n",
    "    if len(data) == 0:\n",
    "        return {}\n",
    "    thetas = {}\n",
    "    for k,v in data[0].items():\n",
    "        thetas[k] = 0\n",
    "    return thetas\n",
    "\n",
    "def plot(x, y, c='black'):\n",
    "    plt.scatter(x, y, color= c)\n",
    "\n",
    "    plt.xticks()\n",
    "    plt.yticks()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by number of iterations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#       STOCHASTIC ALGORITHM        #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "# Parameters:\n",
    "\n",
    "learningRate    = 1e-03\n",
    "max_iterations  = 1000000\n",
    "batch_size      = 10\n",
    "stopCondition   = 1e-03\n",
    "\n",
    "\n",
    "thetas     = init_thetas(dataset_train)\n",
    "done       = False\n",
    "m          = len(dataset_train)\n",
    "iterations = 0\n",
    "\n",
    "# After j_step iterations, compute cost function\n",
    "j_step      = 10\n",
    "costs       = []\n",
    "itr_numbers = []\n",
    "\n",
    "# print(calculate_cost_function(thetas, train_df, target_train_df))\n",
    "\n",
    "# In the Stochastic mode, the error is calculated using only one row of the data set\n",
    "# We'll use them one by one \n",
    "row = 0\n",
    "while(iterations < max_iterations and not done):\n",
    "    \n",
    "    new_thetas = thetas.copy() \n",
    "        \n",
    "    # For each theta we do the following\n",
    "    for k1,v1 in thetas.items():\n",
    "        h = 0\n",
    "        \n",
    "        for k2,v2 in thetas.items():\n",
    "            h += v2 * dataset_train[row][k2]\n",
    "\n",
    "        # Updating the new thetas vector values\n",
    "        new_thetas[k1] = v1 - (learningRate * (h - float(target_train[row])) * dataset_train[row][k1])\n",
    "        \n",
    "    # Updating row that will be used to calculate the error\n",
    "    row = (row + 1) % m\n",
    "    \n",
    "    if iterations % j_step == 0:\n",
    "        costs.append(calculate_cost_function(thetas, dataset_train, target_train))\n",
    "        itr_numbers.append(iterations)\n",
    "        \n",
    "    # If the change in value for new thetas is too small, we can stop iterating\n",
    "    done = True\n",
    "    for k,v in thetas.items():\n",
    "        done = abs(thetas[k] - new_thetas[k]) < stopCondition and done    \n",
    "        \n",
    "     # Atualization of the values of the thetas\n",
    "    thetas = new_thetas.copy()\n",
    "    iterations = iterations + 1\n",
    "    \n",
    "if iterations >= max_iterations:\n",
    "    print(\"Stopped by number of iterations\\n\")\n",
    "if done:\n",
    "    print(\"Stopped by convergence\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients: \\n\")\n",
    "pp.pprint(thetas)\n",
    "\n",
    "plot(itr_numbers, costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by number of iterations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#     BATCH GRADIENT ALGORITHM      #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "# Parameters:\n",
    "\n",
    "learningRate    = 1e-03\n",
    "max_iterations  = 100\n",
    "batch_size      = 10\n",
    "stopCondition   = 1e-03\n",
    "\n",
    "\n",
    "thetas     = init_thetas(dataset_train)\n",
    "done       = False\n",
    "m          = len(dataset_train)\n",
    "iterations = 0\n",
    "\n",
    "# After j_step iterations, compute cost function\n",
    "j_step      = 10\n",
    "costs       = []\n",
    "itr_numbers = []\n",
    "\n",
    "\n",
    "while(iterations < max_iterations and not done):\n",
    "    \n",
    "    new_thetas = thetas.copy()\n",
    "    \n",
    "    # For each theta we do the following\n",
    "    for key,item in thetas.items():\n",
    "        \n",
    "        s = 0\n",
    "        # We add every row of the dataset to the error calculation (Batch)\n",
    "        for i in range(len(dataset_train)):\n",
    "            \n",
    "            h = 0\n",
    "            # Calculating the value for theta\n",
    "            for kt,it in thetas.items():\n",
    "                h += thetas[kt] * dataset_train[i][kt]\n",
    "                \n",
    "            s += (h - float(target_train[i])) * dataset_train[i][key]\n",
    "        \n",
    "        # Updating the new thetas vector values\n",
    "        new_thetas[key] = thetas[key] - ((learningRate / m) * s)\n",
    "    \n",
    "    if iterations % j_step == 0:\n",
    "        costs.append(calculate_cost_function(thetas, dataset_train, target_train))\n",
    "        itr_numbers.append(iterations)\n",
    "    \n",
    "    # If the change in value for new thetas is too small, we can stop iterating\n",
    "    done = True\n",
    "    for k,v in thetas.items():\n",
    "        done = abs(thetas[k] - new_thetas[k]) < stopCondition and done\n",
    "\n",
    "    # Atualization of the values of the thetas\n",
    "    thetas = new_thetas.copy()\n",
    "    iterations = iterations + 1\n",
    "    \n",
    "if iterations >= max_iterations:\n",
    "    print(\"Stopped by number of iterations\\n\")\n",
    "if done:\n",
    "    print(\"Stopped by convergence\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      "\n",
      "{   'carat': -1.029701330902258,\n",
      "    'clarity': -0.38942557089576785,\n",
      "    'color': 0.07596207114659047,\n",
      "    'cut': 0.8308993107810421,\n",
      "    'depth': 0.023345018751861596,\n",
      "    'table': -0.32077821146352653,\n",
      "    'x': 0.5010457284829412,\n",
      "    'x0': 3.9325155619533687,\n",
      "    'y': -1.5163804125456388,\n",
      "    'z': -1.4525187379860882}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Coefficients: \\n\")\n",
    "pp.pprint(thetas)\n",
    "\n",
    "plot(itr_numbers, costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by number of iterations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#   MINI BATCH GRADIENT ALGORITHM   #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "# Parameters:\n",
    "\n",
    "learningRate    = 1e-03\n",
    "max_iterations  = 100000\n",
    "batch_size      = 10\n",
    "stopCondition   = 1e-03\n",
    "\n",
    "\n",
    "thetas     = init_thetas(dataset_train)\n",
    "done       = False\n",
    "m          = len(dataset_train)\n",
    "iterations = 0\n",
    "\n",
    "# After j_step iterations, compute cost function\n",
    "j_step      = 1000\n",
    "costs       = []\n",
    "itr_numbers = []\n",
    "\n",
    "\n",
    "while(iterations < max_iterations and not done):\n",
    "    \n",
    "    # Step through the dataset in chuncks\n",
    "    for row in range(0, len(dataset_train), batch_size):\n",
    "        new_thetas = thetas.copy()\n",
    "        \n",
    "        # For each theta we do the following\n",
    "        for k,val in thetas.items():\n",
    "\n",
    "            s = 0\n",
    "            # We add every row of the dataset to the error calculation (Batch)\n",
    "            for offset in range(batch_size):\n",
    "                if row + offset >= m:\n",
    "                    break\n",
    "                \n",
    "                h = 0\n",
    "                # Calculating the value for theta\n",
    "                for i,v in thetas.items():\n",
    "                    h += thetas[i] * dataset_train[row+offset][i]\n",
    "\n",
    "                s += (h - float(target_train[row+offset])) * dataset_train[row+offset][k]\n",
    "\n",
    "            # Updating the new thetas vector values\n",
    "            new_thetas[k] = thetas[k] - ((learningRate / batch_size) * s)\n",
    "        \n",
    "        if iterations % j_step == 0:\n",
    "            costs.append(calculate_cost_function(thetas, dataset_train, target_train))\n",
    "            itr_numbers.append(iterations)\n",
    "        \n",
    "        iterations = iterations + 1\n",
    "        if iterations >= max_iterations:\n",
    "            break\n",
    "            \n",
    "        # If the change in value for new thetas is too small, we can stop iterating\n",
    "        done = True\n",
    "        for k,v in thetas.items():\n",
    "            done = abs(thetas[k] - new_thetas[k]) < stopCondition and done\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        # Atualization of the values of the thetas\n",
    "        thetas = new_thetas.copy()\n",
    "    \n",
    "if iterations >= max_iterations:\n",
    "    print(\"Stopped by number of iterations\\n\")\n",
    "if done:\n",
    "    print(\"Stopped by convergence\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients: \\n\")\n",
    "pp.pprint(thetas)\n",
    "\n",
    "plot(itr_numbers, costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   454.66548112]\n",
      " [  2786.81982383]\n",
      " [-10003.47913586]\n",
      " [ 24592.08801244]\n",
      " [  -127.34095635]\n",
      " [-10349.14729871]\n",
      " [ 56396.15665186]\n",
      " [  1940.31623813]\n",
      " [ -4392.06386144]\n",
      " [  3515.0095121 ]]\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#          NORMAL EQUATION          #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "mat_train = []\n",
    "mat_target = []\n",
    "for row in range(len(dataset_train)):\n",
    "    mat_train.append([])\n",
    "    mat_target.append([target_train[row]])\n",
    "    for col in dataset_train[row]:\n",
    "        mat_train[row].append(dataset_train[row][col])\n",
    "\n",
    "mat_train = np.matrix(mat_train)\n",
    "mat_train_T = mat_train.transpose()\n",
    "mat_target = np.matrix(mat_target)\n",
    "\n",
    "thetas = np.matmul(np.matmul(inv(np.matmul(mat_train_T, mat_train)), mat_train_T), mat_target)\n",
    "\n",
    "print(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.47258228430606\n"
     ]
    }
   ],
   "source": [
    "mat_test = []\n",
    "for row in range(len(dataset_test)):\n",
    "    mat_test.append([])\n",
    "    for col in dataset_test[row]:\n",
    "        mat_test[row].append(dataset_test[row][col])\n",
    "\n",
    "res = []\n",
    "for rows in mat_test:\n",
    "    res.append(np.matmul(rows,thetas)[0,0])\n",
    "\n",
    "error = 0\n",
    "for i in range(len(res)):\n",
    "    error += abs(target_test[i] - res[i]) / target_test[i]\n",
    "error /= len(res)\n",
    "print(error * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#     SKLEARN LINEAR REGRESSION     #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "\n",
    "dt = []\n",
    "for row in range(len(dataset_train)):\n",
    "    dt.append([])\n",
    "    for col in dataset_train[row]:\n",
    "        dt[row].append(dataset_train[row][col])\n",
    "dtest = []\n",
    "for row in range(len(dataset_test)):\n",
    "    dtest.append([])\n",
    "    for col in dataset_test[row]:\n",
    "        dtest[row].append(dataset_test[row][col])\n",
    "# Create linear regression object\n",
    "regr = linear_model.SGDRegressor(max_iter=100000, eta0=0.0001)\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(dt, target_train)\n",
    "\n",
    "# Make predictions using the validation set\n",
    "diabetes_y_pred = regr.predict(dtest)\n",
    "\n",
    "# Print predictions \n",
    "print(diabetes_y_pred)\n",
    "print(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

\documentclass[conference]{IEEEtran}

\usepackage[utf8]{inputenc}

\PassOptionsToPackage{bookmarks=false}{hyperref}

\usepackage{amsmath}
\usepackage{float}

\usepackage{listings}
\usepackage{color}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage[caption=true,font=footnotesize]{subfig}
\usepackage[hidelinks]{hyperref}

\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage[portuguese, english]{babel}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{textcomp}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Estudos em Regressão Linear}

\author{\IEEEauthorblockN{Matheus Mortatti Diamantino}
\IEEEauthorblockA{
RA 156740 \\
matheusmortatti@gmail.com}
\and
\IEEEauthorblockN{Jos\'{e} Renato Vicente}
\IEEEauthorblockA{
RA 155984\\
joserenatovi@gmail.com}}

\maketitle

\section{Introduction}

Este projeto teve como intuito o estudo prático do método de regressão linear em Machine Learning. Foram utilizado os algoritmos de \textit{Gradient Descent} conhecidos como \textit{Stochastic, Batch, Mini Batch e Equação Normal}, de modo a compara-los em termos de complexidade e acurácia.

Foi feito um estudo de predição de preço de diamantes, utilizando uma base de dados com 54000 exemplos, em que são apresentados seus preços e nove features como tamanho, cor e número de quilates.

\section{Activities}

\subsection{Regressão Linear}

Regressão Linear é um método muito conhecido de Machine Learning, utilizado para predizer o valor de uma variável dependente baseado em valores de variáveis independentes. Essa regressão é chamada linear porque se considera que a relação da resposta às variáveis é uma função linear de alguns parâmetros. Desta forma, dado um vetor Theta de tamanho igual ao número de features, cujo valor queremos determinar, temos que:

\begin{equation} \label{eq:hx}
PreçoAlvoEsperado = \sum_{i=1}^{m} \theta_{i}X_{i} = h_{\theta}(x)
\end{equation}

Em que X é um vetor com os valores das features para um dado diamante, cujo preço queremos determinar.Para encontrar esse valor de Theta, utilizaremos alguns algoritmos e compararemos os resultados obtidos com cada um.

Cada algoritmo utilizado é baseado no método de \textit{Descrida de Gradiente (ou Gradient Descent)}. Este é um método utilizado para achar o ponto mínimo de uma função, aproximando gradativamente seu valor até um ponto quando não é possível ser diminuido mais (i.e. a derivada da função neste ponto é zero). Este método consegue apenas achar mínimos locais e, com isso, não é garantido que o resultado obtido é o melhor para o dado problema.

Para medirmos a eficácia do algoritmo, utilizamos uma \textit{Função de Custo} que nos diz o quão perto do resultado desejado estamos, dado um conjunto de dados. Esta função é definida por:

\begin{equation} \label{eq:cost_function}
J(\theta) = \dfrac{1}{2m} \sum_{i=1}^{m}(h_{\theta}(x^{i}) - y^{i})^2
\end{equation}

Como queremos minimizar a função de custo, queremos que cada passo da nossa descida de gradiente se aproxime mais do mínimo local. Para extrairmos a direção que temos que ir, utilizamos a derivada da função de custo:

\begin{equation} \label{eq:cost_derivative}
\dfrac{\partial J}{\partial \theta_{j}} = \dfrac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{i}) - y^{i}) x^{i}
\end{equation}

Logo, para aproximarmos os valores de $\theta$ de modo a nos aproximar do mínimo local, utilizamos a fórmula

\begin{equation} \label{eq:gradient_descent}
\theta_{j} := \theta_{j} - \alpha \dfrac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{i}) - y^{i}) x^{i}
\end{equation}

, onde $0 \leq j \leq m$, $x_{0} = 1$ e $\alpha$ é o que chamamos de \textit{Learning Rate} que define o quão agressivamente tentaremos nos aproximar do mínimo. Este método de descida de gradiente é chamada de \textit{Batch Gradient Descent}. A seguir, veremos três outras variações deste algoritmo

\paragraph{Stochastic Gradient Descent}

Neste método, utiliza-se apenas um exemplo de treino para cada passo da descida de gradiente. Deste modo, a equação~\ref{eq:gradient_descent} se transforma em

\begin{equation} \label{eq:stochastic_descent}
\theta_{j} := \theta_{j} - \alpha(h_{\theta}(x^{i}) - y^{i}) x^{i}
\end{equation}

Utiliza-se este método quando procura-se rapidez de execução. Contudo, um ponto negativo deste método é que, como usamos como amostra apenas um exemplo de treino, um passo pode nos levar a um custo mais alto. Como o número de iterações é alta, porém, o método converge ao mínimo e mais eficientemente do que o \textit{Batch} até um certo limite.

\paragraph{Mini Batch Gradient Descent}

Para obtermos um resultado balanceado, utiliza-se uma mistura dos métodos \textit{Batch} e \textit{Stochastic}, em que define-se um tamanho para o lote de exemplos de treino que serão utilizados para atualizar cara $\theta$.

\begin{equation} \label{eq:minibatch_descent}
\theta_{j} := \theta_{j} - \alpha \dfrac{1}{m} \sum_{i=k}^{k+b-1}(h_{\theta}(x^{i}) - y^{i}) x^{i}
\end{equation}

, onde $b$ é o tamanho do lote, $k = 0, b, 2b, ..., m-1$.

\paragraph{Equação Normal}

Para a regressão linear, é possível derivar uma fórmula direta para o ponto de mínimo local que desejamos. Para isso, utilizamos manipulações matriciais na forma

\begin{equation} \label{eq:normal}
\theta = (X^{T}X)^{-1}X^{T}y
\end{equation}

, onde $X$ é a matriz de features, $y$ é a matriz dos dados que queremos prever e $\theta$ é a matriz dos coeficientes de $h(X)$.

\subsection{Normalização de Features}

Como cada feature tem seu valor em uma escala diferente (i.e. algumas estão na ordem de milhares e outras na ordem de centenas), o processo de descida do gradiente poderá acontecer de forma lenta. Isso se dá pelo fato de que a atualização dos $\theta$s não ocorrerá de forma uniforme entre as features, já que a distância de um dado $\theta_{i}$ a seu valor esperado pode ser maior do que de outro $\theta_{j}, j \neq i$. Assim, realizamos o que é chamado de \textit{Normalização de Features}, onde colocamos todas as features $x_{i}$ em um valor entre $ \-0.5 \leq x_{i} \leq 0.5$. Isso é feito através da fórmula:

\begin{equation} \label{eq:feature_norm}
x_{i} = \dfrac{x_{i} - \dfrac{size(x_{i})}{2}}{size(x_{i})}
\end{equation}

\subsection{Transformação de Features}

Em alguns casos, podemos ter features que não possuem um valor no domínio dos números reais. Por exemplo, uma feature pode representar a cor de um dado elemento. Deste modo, é necessário realizar uma transformação de tais features para o domínio dos reais. Para realizar tal transformação, criamos uma nova feature para cada possível valor da feature que queremos transformar, de modo que, se para o exemplo de dado $e_{i}$ temos que esta feature possui um valor $x_{j}$, a nova feature correspondente a $x_{j}$ terá o valor $1$ e as demais features criadas terão o valor $0$. Tomemos como exemplo uma feature de Cor que pode receber os valores \textit{Azul, Amarelo, Vermelho e Verde}. Assim, o resultado da transformação acontecerá da seguinte forma:

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
Feature $x_{i}$ & Azul & Amarelo & Vermelho & Verde \\ \hline
Azul            & 1    & 0       & 0        & 0     \\ \hline
Amarelo         & 0    & 1       & 0        & 0     \\ \hline
Vermelho        & 0    & 0       & 1        & 0     \\ \hline
Verde           & 0    & 0       & 0        & 1     \\ \hline
\end{tabular}
\end{table}

Onde cada coluna representa a nova feature criada e cada linha representa o valor original da feature $x_{i}$.

\subsection{Regularização}

Regularização é um método utilizado para \textit{evitar} overfitting dos dados. É relizado de forma a penalizar os valores de $\theta$ para que estes mantenham valores pequenos, sendo menos propenso ao overfitting. Isto é feito na forma de um novo parâmetro $\lambda$ que definirá o quanto cada $\theta$ será penalizado:

\begin{equation} \label{eq:regularization}
\theta_{j} := \theta_{j} * (1 - \lambda * \dfrac{\alpha}{m}) - \alpha \dfrac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{i}) - y^{i}) x^{i}
\end{equation}

Este valor deve ser modificado de forma a melhorar o resultado final. Se o valor for muito alto, a influência da regularização pode ser negativa, criando um aumento no erro final. Se muito baixo, não terá o efeito desejado. Vale mencionar que a regularização na equação normal se da pela forma

\begin{equation} \label{eq:normal_reg}
\theta = (X^{T}X + \lambda I)^{-1}X^{T}y
\end{equation}

, onde $I$ é a matriz identidade.

\section{Proposed Solutions}



\section{Experiments and Discussion}

\begin{figure*}[h]
	\centering
	\subfloat[lambda = 0.0000005, learning rate = 0.01]{
		\includegraphics[width=0.5\linewidth]{gfx/S_costitr_mitr5000000.png}
		\label{fig:sto_5m}
	}
\end{figure*}



\section{Conclusions and Future Work}

The main conclusions of the work as well as some future directions for other people interested in continuing this work. ~\cite{b1}

\bibliographystyle{IEEEtran}
\bibliography{biblio-link,biblio}

\end{document}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Code source adapted from: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import os\n",
    "import csv\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_dataset(dataset):\n",
    "    vcut = {'Fair': 0, 'Good': 1, 'Very Good': 2, 'Premium': 3, 'Ideal': 4}\n",
    "    vcolor = {'D': 6, 'E': 5, 'F': 4, 'G': 3, 'H': 2, 'I': 1, 'J': 0}\n",
    "    vclarity = {'I1': 0, 'SI2': 1, 'SI1': 2, 'VS2': 3, 'VS1': 4, 'VVS2': 5, 'VVS1': 6, 'IF': 7}\n",
    "    \n",
    "    target = []\n",
    "    new_data = []\n",
    "    for row in dataset:\n",
    "        # Modify string to number values\n",
    "#         row[\"cut\"] = vcut[row[\"cut\"]]\n",
    "#         row[\"color\"] = vcolor[row[\"color\"]]\n",
    "#         row[\"clarity\"] = vclarity[row[\"clarity\"]]\n",
    "        \n",
    "        new_data.append([])\n",
    "        nrow = new_data[len(new_data)-1]\n",
    "        \n",
    "        # Add X0 for ease of use\n",
    "        nrow.append(1)\n",
    "        \n",
    "        # Create new values\n",
    "        row[\"carat2\"] = float(row[\"carat\"])**2\n",
    "        row[\"table2\"] = float(row[\"table\"])**2\n",
    "        row[\"depth2\"] = float(row[\"depth\"])**2\n",
    "        row[\"x2\"] = float(row[\"x\"])**2\n",
    "        row[\"y2\"] = float(row[\"y\"])**2\n",
    "        row[\"z2\"] = float(row[\"z\"])**2\n",
    "        \n",
    "        row[\"carat3\"] = float(row[\"carat\"])**3\n",
    "        row[\"table3\"] = float(row[\"table\"])**3\n",
    "        row[\"depth3\"] = float(row[\"depth\"])**3\n",
    "        row[\"x3\"] = float(row[\"x\"])**3\n",
    "        row[\"y3\"] = float(row[\"y\"])**3\n",
    "        row[\"z3\"] = float(row[\"z\"])**3\n",
    "        \n",
    "        row[\"carat4\"] = float(row[\"carat\"])**4\n",
    "        row[\"table4\"] = float(row[\"table\"])**4\n",
    "        row[\"depth4\"] = float(row[\"depth\"])**4\n",
    "        row[\"x4\"] = float(row[\"x\"])**4\n",
    "        row[\"y4\"] = float(row[\"y\"])**4\n",
    "        row[\"z4\"] = float(row[\"z\"])**4\n",
    "        \n",
    "        row[\"xyz\"] = float(row[\"x\"]) * float(row[\"y\"]) * float(row[\"z\"])\n",
    "        \n",
    "        # Normalize values\n",
    "        \n",
    "#         nrow.append((float(row[\"cut\"]) - (4/2))/(4))\n",
    "#         nrow.append((float(row[\"color\"]) - (6/2))/(6))\n",
    "#         nrow.append((float(row[\"clarity\"]) - (7/2))/(7))\n",
    "\n",
    "        nrow.append(((float(row[\"carat\"]) - (0.2+5.01)/2)/((0.2+5.01))))\n",
    "        nrow.append((float(row[\"x\"]) - (10.74/2))/(10.74))\n",
    "        nrow.append((float(row[\"y\"]) - (58.9/2))/(58.9))\n",
    "        nrow.append((float(row[\"z\"]) - (31.8/2))/(31.8))\n",
    "        nrow.append((float(row[\"depth\"]) - (43+79)/2)/(43+79))\n",
    "        nrow.append((float(row[\"table\"]) - (43+95)/2)/(43+95))\n",
    "        \n",
    "#         nrow.append(((float(row[\"carat2\"]) - (0.2+5.01)**2/2)/((0.2+5.01)**2)))\n",
    "#         nrow.append((float(row[\"x2\"]) - (10.74**2/2))/(10.74**2))\n",
    "#         nrow.append((float(row[\"y2\"]) - (58.9**2/2))/(58.9**2))\n",
    "#         nrow.append((float(row[\"z2\"]) - (31.8**2/2))/(31.8**2))\n",
    "#         nrow.append((float(row[\"depth2\"]) - (122)**2/2)/(122**2))\n",
    "#         nrow.append((float(row[\"table2\"]) - (138)**2/2)/(138**2))\n",
    "        \n",
    "#         nrow.append(((float(row[\"carat3\"]) - (0.2+5.01)**3/2)/((0.2+5.01)**3)))\n",
    "#         nrow.append((float(row[\"x3\"]) - (10.74**3/2))/(10.74**3))\n",
    "#         nrow.append((float(row[\"y3\"]) - (58.9**3/2))/(58.9**3))\n",
    "#         nrow.append((float(row[\"z3\"]) - (31.8**3/2))/(31.8**3))\n",
    "#         nrow.append((float(row[\"depth3\"]) - (122)**3/2)/(122**3))\n",
    "#         nrow.append((float(row[\"table3\"]) - (138)**3/2)/(138**3))\n",
    "        \n",
    "#         nrow.append(((float(row[\"carat4\"]) - (0.2+5.01)**4/2)/((0.2+5.01)**4)))\n",
    "#         nrow.append((float(row[\"x4\"]) - (10.74**4/2))/(10.74**4))\n",
    "#         nrow.append((float(row[\"y4\"]) - (58.9**4/2))/(58.9**4))\n",
    "#         nrow.append((float(row[\"z4\"]) - (31.8**4/2))/(31.8**4))\n",
    "#         nrow.append((float(row[\"depth4\"]) - (122)**4/2)/(122**4))\n",
    "#         nrow.append((float(row[\"table4\"]) - (138)**4/2)/(138**4))\n",
    "        \n",
    "        # Add values for cut, color and clarity with Grid method\n",
    "        for k,v in vcolor.items():\n",
    "            nrow.append(1 if row[\"color\"]==k else 0)\n",
    "        for k,v in vcut.items():\n",
    "            nrow.append(1 if row[\"cut\"]==k else 0)\n",
    "        for k,v in vclarity.items():\n",
    "            nrow.append(1 if row[\"clarity\"]==k else 0)\n",
    "        \n",
    "        # Remove target element and insert into it's own list\n",
    "        target.append(float(row[\"price\"]))\n",
    "    return new_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and treat training dataset\n",
    "dataset_train = []\n",
    "reader = csv.DictReader(open('diamonds-train.csv', 'r'))\n",
    "for line in reader:\n",
    "     dataset_train.append(line)\n",
    "\n",
    "dataset_train, target_train = treat_dataset(dataset_train)\n",
    "\n",
    "# Read and treat test dataset\n",
    "dataset_test = []\n",
    "reader = csv.DictReader(open('diamonds-test.csv', 'r'))\n",
    "for line in reader:\n",
    "     dataset_test.append(line)\n",
    "\n",
    "dataset_test, target_test = treat_dataset(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost_function(thetas, data, target, _lambda):\n",
    "    m = len(data)\n",
    "    s = 0\n",
    "    \n",
    "    # Regularization term\n",
    "    reg = 0\n",
    "    for t in range(len(data[0])):\n",
    "        reg += thetas[t] * thetas[t]\n",
    "    reg *= _lambda\n",
    "        \n",
    "    for index in range(len(data)):\n",
    "        h = 0\n",
    "        h += thetas[0]\n",
    "        for k in range(1, len(data[index])):\n",
    "            h += thetas[k] * data[index][k]\n",
    "        s += (h - float(target[index]))*(h - float(target[index]))\n",
    "    return (1/(2*m)) * (s + reg)\n",
    "\n",
    "def calculate_hfunction(features, thetas):\n",
    "    h = 0\n",
    "    for f in range(len(thetas)):\n",
    "        h += thetas[f] * features[f]\n",
    "    return h\n",
    "\n",
    "def init_thetas(data):\n",
    "    if len(data) == 0:\n",
    "        return []\n",
    "    thetas = []\n",
    "    for k in range(len(data[0])):\n",
    "        thetas.append(0)\n",
    "    return thetas\n",
    "\n",
    "def get_predictions(data, thetas):\n",
    "    res = []\n",
    "    for row in range(len(data)):\n",
    "        res.append(np.matmul([data[row]],np.column_stack([thetas]))[0,0])\n",
    "    return res\n",
    "\n",
    "def graph_add_scatter(x, y, c='black'):\n",
    "    plt.scatter(x, y, color= c)\n",
    "\n",
    "def graph_add_line(x, y, c='black'):\n",
    "    plt.plot(x, y, color=c, linewidth=3)\n",
    "\n",
    "def plot(name=\"\"):\n",
    "    plt.xticks()\n",
    "    plt.yticks()\n",
    "    \n",
    "    if name!=\"\":\n",
    "        plt.savefig(name)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def current_time():\n",
    "    return int(round(time.time() * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#    GRADIENT DESCENT ALGORITHM     #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "#\n",
    "# data = dataset used for fitting\n",
    "#\n",
    "# target = values the user wants to predict\n",
    "#\n",
    "# batch_size = ammount of data used to update coeficients. \n",
    "#              Use 1 for Stochastic, 1 < n < size(data) for Mini Batch and size(data) for Batch\n",
    "#\n",
    "# max_iterations = number of maximum iterations used for fitting. Might not reach this value\n",
    "#                  if other conditions are reached\n",
    "#\n",
    "# stopCondition = minimum difference between new and old coefficients that will stop the algorithm\n",
    "#\n",
    "# learningRate = alpha value\n",
    "#\n",
    "# j_step = number of iterations before calculating and keeping current cost value\n",
    "#\n",
    "# _lambda = regularization term\n",
    "####################################################################################################\n",
    "\n",
    "def gradient_descent(data, target, batch_size = 1, max_iterations = 100, stopCondition = 1e-04, learningRate = 1e-03, j_step=1000, _lambda = 0.01):\n",
    "\n",
    "    thetas     = init_thetas(data)\n",
    "    done       = False\n",
    "    m          = len(data)\n",
    "    iterations = 0\n",
    "\n",
    "    # After j_step iterations, compute cost function\n",
    "    costs       = []\n",
    "    itr_numbers = []\n",
    "    \n",
    "    retryCount = 0\n",
    "    retryMax = 1000\n",
    "\n",
    "    startTime = current_time()\n",
    "    while(iterations < max_iterations and not done):\n",
    "\n",
    "        # Step through the dataset in chuncks\n",
    "        for row in range(0, len(data), batch_size):\n",
    "            new_thetas = thetas.copy()\n",
    "            \n",
    "            # Update theta 0 \n",
    "            s = 0\n",
    "            for offset in range(batch_size):\n",
    "                if row + offset >= m:\n",
    "                    break\n",
    "                h = calculate_hfunction(data[row+offset], thetas)\n",
    "                s = (h - float(target[row+offset])) * data[row+offset][0]\n",
    "                \n",
    "            new_thetas[0] = thetas[0] - ((learningRate / batch_size) * s)\n",
    "\n",
    "            # For each theta we do the following\n",
    "            for k in range(1, len(thetas)):\n",
    "\n",
    "                s = 0\n",
    "                # We add every row of the dataset to the error calculation (Batch)\n",
    "                for offset in range(batch_size):\n",
    "                    if row + offset >= m:\n",
    "                        break\n",
    "\n",
    "                    h = calculate_hfunction(data[row+offset], thetas)\n",
    "\n",
    "                    s += (h - float(target[row+offset])) * data[row+offset][k]\n",
    "\n",
    "                # Updating the new thetas vector values\n",
    "                new_thetas[k] = thetas[k] * (1 - _lambda * learningRate / batch_size) - (learningRate * (s / batch_size))\n",
    "            \n",
    "            # keep a new cost value\n",
    "            if iterations % j_step == 0:\n",
    "                cost = calculate_cost_function(thetas, data, target, _lambda)\n",
    "                if len(costs)>0 and cost > costs[-1]:\n",
    "                    learningRate /= 1.001\n",
    "                    if retryCount < retryMax:\n",
    "                        retryCount+=1\n",
    "                    else:\n",
    "                        iterations = max_iterations\n",
    "                else:\n",
    "                    retryCount = 0\n",
    "                costs.append(cost)\n",
    "                itr_numbers.append(iterations)\n",
    "                \n",
    "            iterations = iterations + 1\n",
    "            if iterations >= max_iterations:\n",
    "                break\n",
    "\n",
    "            # If the change in value for new thetas is too small, we can stop iterating\n",
    "            done = True\n",
    "            for k in range(len(thetas)):\n",
    "                done = abs(thetas[k] - new_thetas[k]) < stopCondition and done\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            # Atualization of the values of the thetas\n",
    "            thetas = new_thetas.copy()\n",
    "\n",
    "    if iterations >= max_iterations:\n",
    "        print(\"Stopped by number of iterations\\n\")\n",
    "    if done:\n",
    "        print(\"Stopped by convergence\\n\")\n",
    "        \n",
    "    endTime = current_time()\n",
    "    print(\"RunTime = \", (endTime - startTime)/1000, \" seconds\")\n",
    "    \n",
    "    return thetas, itr_numbers, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1b72e603e221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mb_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mthetas_mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitr_numbers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0000005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopCondition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00000000001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-f67ff13d55ac>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(data, target, batch_size, max_iterations, stopCondition, learningRate, j_step, _lambda)\u001b[0m\n\u001b[1;32m     67\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_hfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-87610d07cb89>\u001b[0m in \u001b[0;36mcalculate_hfunction\u001b[0;34m(features, thetas)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#   MINI BATCH GRADIENT ALGORITHM   #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "max_iter=20000\n",
    "b_size=1000\n",
    "thetas_mbatch, itr_numbers, costs = gradient_descent(dataset_train, target_train, _lambda=0.0000005, stopCondition = 0.00000000001, learningRate=1e-02, max_iterations=max_iter, j_step=1000, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients: \\n\")\n",
    "pp.pprint(thetas_mbatch)\n",
    "\n",
    "print(\"\\nMean absolute error: %.2f\"\n",
    "      % mean_absolute_error(target_train, get_predictions(dataset_train, thetas_mbatch)))\n",
    "\n",
    "print(\"\\nFinal Cost: %.2f\\n\"\n",
    "      % costs[-1])\n",
    "\n",
    "graph_add_line(itr_numbers, costs)\n",
    "plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#     BATCH GRADIENT ALGORITHM      #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "max_iter=1000\n",
    "thetas_batch, itr_numbers_batch, costs_batch = gradient_descent(dataset_train, target_train, _lambda=0.0000005, stopCondition = 0.00000001, batch_size=len(dataset_train), learningRate=1e-02, max_iterations=max_iter, j_step=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients: \\n\")\n",
    "pp.pprint(thetas_batch)\n",
    "\n",
    "print(\"\\nMean absolute error: %.2f\"\n",
    "      % mean_absolute_error(target_train, get_predictions(dataset_train, thetas_batch)))\n",
    "\n",
    "print(\"\\nVariance: %.2f\"\n",
    "      % explained_variance_score(target_train, get_predictions(dataset_train, thetas_batch)))\n",
    "\n",
    "print(\"\\nFinal Cost: %.2f\"\n",
    "      % costs_batch[-1])\n",
    "\n",
    "graph_add_line(itr_numbers_batch, costs_batch)\n",
    "plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#       STOCHASTIC ALGORITHM        #\n",
    "#                                   #\n",
    "#####################################\n",
    "max_iter=2000000\n",
    "thetas_sto, itr_numbers_sto, costs_sto = gradient_descent(dataset_train, target_train, _lambda=0.0000005, stopCondition = 0.00000000001, batch_size=1, learningRate=0.0001, max_iterations=max_iter, j_step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients: \\n\")\n",
    "pp.pprint(thetas_sto)\n",
    "\n",
    "print(\"\\nMean absolute error: %.2f\"\n",
    "      % mean_absolute_error(target_train, get_predictions(dataset_train, thetas_sto)))\n",
    "\n",
    "print(\"\\nVariance: %.2f\"\n",
    "      % explained_variance_score(target_train, get_predictions(dataset_train, thetas_sto)))\n",
    "\n",
    "print(\"\\nFinal Cost: %.2f\"\n",
    "      % costs_sto[-1])\n",
    "\n",
    "graph_add_line(itr_numbers_sto, costs_sto)\n",
    "plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunTime =  0.021  seconds\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#          NORMAL EQUATION          #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "mat_target = []\n",
    "\n",
    "for row in range(len(target_train)):\n",
    "    mat_target.append([target_train[row]])\n",
    "\n",
    "mat_train = np.matrix(dataset_train)\n",
    "mat_train_T = mat_train.transpose()\n",
    "mat_target = np.matrix(mat_target)\n",
    "\n",
    "identity = np.identity(len(dataset_train[0]))\n",
    "identity[0,0] = 0\n",
    "_lambda = -1.5\n",
    "\n",
    "startTime = current_time()\n",
    "# thetas = (X^t * X + l * I)^(-1) * X^t * y\n",
    "thetas = (np.matmul(\n",
    "            np.matmul(\n",
    "                inv(\n",
    "                    np.add(\n",
    "                        np.matmul(mat_train_T, mat_train), \n",
    "                        np.multiply(_lambda, identity))), \n",
    "                mat_train_T), \n",
    "            mat_target))\n",
    "\n",
    "# errors = []\n",
    "# lambdas = []\n",
    "\n",
    "# startTime = current_time()\n",
    "# for i in range(1):\n",
    "\n",
    "# # thetas = (X^t * X + l * I)^(-1) * X^t * y\n",
    "#     thetas = (np.matmul(\n",
    "#                 np.matmul(\n",
    "#                     inv(\n",
    "#                         np.add(\n",
    "#                             np.matmul(mat_train_T, mat_train), \n",
    "#                             np.multiply(_lambda, identity))), \n",
    "#                     mat_train_T), \n",
    "#                 mat_target))\n",
    "    \n",
    "#     lambdas.append(_lambda)\n",
    "#     errors.append(mean_absolute_error(target_train, get_predictions(dataset_train, thetas)))\n",
    "#     _lambda -= 0.1\n",
    "\n",
    "endTime = current_time()\n",
    "print(\"RunTime = \", (endTime - startTime)/1000, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      "\n",
      "matrix([[ 2.10843399e+04],\n",
      "        [ 6.71715609e+04],\n",
      "        [-1.55776106e+04],\n",
      "        [-5.50313880e+03],\n",
      "        [-8.55202690e+03],\n",
      "        [-1.68267494e+04],\n",
      "        [-8.47316236e+03],\n",
      "        [ 5.76227440e+02],\n",
      "        [-6.64057612e+02],\n",
      "        [ 3.61878159e+02],\n",
      "        [ 6.34286578e+02],\n",
      "        [-1.54966328e+02],\n",
      "        [-1.59768085e+03],\n",
      "        [ 8.44312614e+02],\n",
      "        [ 1.25571910e+02],\n",
      "        [-4.21632776e+02],\n",
      "        [ 1.51082954e+02],\n",
      "        [ 1.13948255e+02],\n",
      "        [ 3.10296567e+01],\n",
      "        [-3.79502691e+03],\n",
      "        [-1.10402358e+03],\n",
      "        [-1.05237997e+02],\n",
      "        [ 1.14864177e+03],\n",
      "        [ 1.12133733e+03],\n",
      "        [ 4.72260000e+02],\n",
      "        [ 1.48218026e+03],\n",
      "        [ 7.79869122e+02]])\n",
      "\n",
      "Mean absolute error Train: 729.33\n",
      "\n",
      "Mean absolute error Validation: 726.32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3455fd79ebbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m print(\"\\nFinal Cost: %2f\"\n\u001b[0;32m---> 11\u001b[0;31m       % calculate_cost_function(thetas, dataset_train, target_train, _lambda))\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# graph_add_line(lambdas, errors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-87610d07cb89>\u001b[0m in \u001b[0;36mcalculate_cost_function\u001b[0;34m(thetas, data, target, _lambda)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: \\n\")\n",
    "pp.pprint(thetas)\n",
    "\n",
    "print(\"\\nMean absolute error Train: %.2f\"\n",
    "      % mean_absolute_error(target_train, get_predictions(dataset_train, thetas)))\n",
    "\n",
    "print(\"\\nMean absolute error Validation: %.2f\"\n",
    "      % mean_absolute_error(target_test, get_predictions(dataset_test, thetas)))\n",
    "\n",
    "print(\"\\nFinal Cost: %2f\"\n",
    "      % calculate_cost_function(thetas, dataset_train, target_train, _lambda))\n",
    "\n",
    "# graph_add_line(lambdas, errors)\n",
    "# plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#     SKLEARN LINEAR REGRESSION     #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.SGDRegressor(max_iter=200000, eta0=0.01, alpha=0.0000005)\n",
    "\n",
    "startTime = current_time()\n",
    "# Train the model using the training sets\n",
    "regr.fit(dataset_train, target_train)\n",
    "\n",
    "endTime = current_time()\n",
    "print(\"RunTime = \", (endTime - startTime)/1000, \" seconds\")\n",
    "\n",
    "# Make predictions using the validation set\n",
    "y_pred = regr.predict(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "coef = regr.intercept_.tolist() + regr.coef_.tolist()\n",
    "print('Coefficients: \\n', coef)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"\\nMean absolute error: %.2f\"\n",
    "      % mean_absolute_error(target_train, y_pred))\n",
    "\n",
    "print(\"\\nFinal Cost: %2f\"\n",
    "      % regr.score(pd.DataFrame(dataset_train), target_train))\n",
    "\n",
    "print(regr.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#    RESULTS FOR VALIDATION DATA    #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "print(\"scikit-learn: \\n\")\n",
    "\n",
    "y_pred_val = regr.predict(dataset_test)\n",
    "\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(target_test, y_pred_val))\n",
    "s\n",
    "\n",
    "print(\"\\n\\nNormal Equation: \\n\")\n",
    "\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(target_test, get_predictions(dataset_test, thetas)))\n",
    "\n",
    "\n",
    "print(\"\\n\\nStochastic: \\n\")\n",
    "\n",
    "print(\"Mean absolute error: %.2f\"\n",
    "      % mean_absolute_error(target_test, get_predictions(dataset_test, thetas_sto)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

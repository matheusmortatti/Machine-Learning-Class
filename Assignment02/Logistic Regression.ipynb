{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import os\n",
    "import csv\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training dataset\n",
    "dataset_train = []\n",
    "reader = csv.DictReader(open('fashion-mnist-dataset/fashion-mnist_train.csv', 'r'))\n",
    "for line in reader:\n",
    "     dataset_train.append(line)\n",
    "        \n",
    "# Read test dataset\n",
    "dataset_test = []\n",
    "reader = csv.DictReader(open('fashion-mnist-dataset/fashion-mnist_test.csv', 'r'))\n",
    "for line in reader:\n",
    "     dataset_test.append(line)\n",
    "        \n",
    "# Making a target dataset for each clothing option\n",
    "# Finding out min and max values\n",
    "min = 0\n",
    "max = 0\n",
    "\n",
    "for row in range(len(dataset_train)):\n",
    "    if int(dataset_train[row][\"label\"]) < min:\n",
    "        min = int(dataset_train[row][\"label\"])\n",
    "        \n",
    "    if int(dataset_train[row][\"label\"]) > max:\n",
    "        max = int(dataset_train[row][\"label\"])\n",
    "size = max - min + 1\n",
    "\n",
    "dataset_train_target = np.zeros((size, len(dataset_train)))\n",
    "\n",
    "for row in range(len(dataset_train)):\n",
    "    x = int(dataset_train[row][\"label\"])\n",
    "    dataset_train_target[x][row] = 1\n",
    "    \n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_thetas(data, size):\n",
    "    if len(data) == 0:\n",
    "        return []\n",
    "    thetas = np.zeros((size, len(data[0])))\n",
    "    return thetas\n",
    "\n",
    "def sigmoid(val):\n",
    "    return 1 / (1 + math.exp(-val))\n",
    "\n",
    "def calculate_hfunction(features, thetas):\n",
    "    z = 0\n",
    "    z += thetas[0]\n",
    "    for f in range(1, len(thetas)):\n",
    "        z += thetas[f] * features[f-1]\n",
    "    h = sigmoid(z)\n",
    "    return h\n",
    "\n",
    "def calculate_cost_function(thetas, data, target):\n",
    "    m = len(data)\n",
    "    s = 0\n",
    "        \n",
    "    for index in range(len(data)):\n",
    "        h = 0\n",
    "        h += thetas[0]\n",
    "        for k in range(1, len(thetas)):\n",
    "            h += thetas[k] * data[index][k-1]\n",
    "        h = sigmoid(h)\n",
    "        s += (h - float(target[index]))*(h - float(target[index]))\n",
    "    return (1/(2*m)) * (s)\n",
    "\n",
    "def get_predictions(data, thetas):\n",
    "    res = []\n",
    "    for row in range(len(data)):\n",
    "        z = np.matmul([data[row]],np.column_stack([thetas]))\n",
    "        h = sigmoid(z)\n",
    "        res.append(h[0,0])\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#    GRADIENT DESCENT ALGORITHM     #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "\n",
    "def gradient_descent(data, target, thetas, batch_size = 1, max_iterations = 100, stopCondition = 1e-04, learningRate = 1e-03, j_step=1000):\n",
    "    done       = False\n",
    "    m          = len(data)\n",
    "    iterations = 0\n",
    "    \n",
    "    # After j_step iterations, compute cost function\n",
    "    costs       = []\n",
    "    itr_numbers = []\n",
    "    \n",
    "    retryCount = 0\n",
    "    retryMax = 1000\n",
    "\n",
    "    #startTime = current_time()\n",
    "    \n",
    "    while(iterations < max_iterations and not done):\n",
    "        # Step through the dataset in chuncks\n",
    "        for row in range(0, len(data), batch_size):\n",
    "            new_thetas = thetas.copy()\n",
    "            \n",
    "        # Update theta 0 \n",
    "            s = 0\n",
    "            for offset in range(batch_size):\n",
    "                if row + offset >= m:\n",
    "                    break\n",
    "                h = calculate_hfunction(data[row+offset], thetas)\n",
    "                s = (h - float(target[row+offset]))\n",
    "                \n",
    "            new_thetas[0] = thetas[0] - ((learningRate / batch_size) * s)    \n",
    "    \n",
    "            # For each theta we do the following\n",
    "            for k in range(1, len(thetas)):\n",
    "\n",
    "                s = 0\n",
    "                # We add every row of the dataset to the error calculation (Batch)\n",
    "                for offset in range(batch_size):\n",
    "                    if row + offset >= m:\n",
    "                        break\n",
    "\n",
    "                    h = calculate_hfunction(data[row+offset], thetas)\n",
    "                    s += (h - float(target[row+offset])) * data[row+offset][k-1]\n",
    "\n",
    "                # Updating the new thetas vector values\n",
    "                new_thetas[k] = thetas[k] - ((learningRate / batch_size) * s)\n",
    "            \n",
    "            # keep a new cost value\n",
    "            if iterations % j_step == 0:\n",
    "                cost = calculate_cost_function(thetas, data, target)\n",
    "                if len(costs)>0 and cost > costs[-1]:\n",
    "                    learningRate /= 1.001\n",
    "                    if retryCount < retryMax:\n",
    "                        retryCount += 1\n",
    "                    else:\n",
    "                        iterations = max_iterations\n",
    "                else:\n",
    "                    retryCount = 0\n",
    "                costs.append(cost)\n",
    "                itr_numbers.append(iterations)\n",
    "                \n",
    "            iterations = iterations + 1\n",
    "            if iterations >= max_iterations:\n",
    "                break\n",
    "    \n",
    "    \n",
    "             # If the change in value for new thetas is too small, we can stop iterating\n",
    "            done = True\n",
    "            for k in range(len(thetas)):\n",
    "                done = abs(thetas[k] - new_thetas[k]) < stopCondition and done\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            # Atualization of the values of the thetas\n",
    "            thetas = new_thetas.copy()\n",
    "    \n",
    "    if iterations >= max_iterations:\n",
    "        print(\"Stopped by number of iterations\\n\")\n",
    "    if done:\n",
    "        print(\"Stopped by convergence\\n\")\n",
    "        \n",
    "    #endTime = current_time()\n",
    "    #print(\"RunTime = \", (endTime - startTime)/1000, \" seconds\")\n",
    "    \n",
    "    return thetas, itr_numbers, costs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 786)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-42a721e052f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#     BATCH GRADIENT ALGORITHM      #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "thetas = init_thetas(dataset_train, size)\n",
    "thetas_batch = init_thetas(dataset_train, size)\n",
    "\n",
    "\n",
    "print(thetas.shape)\n",
    "\n",
    "for model in range (size):\n",
    "    target_train = dataset_train_target[model]\n",
    "    max_iter = 100\n",
    "    \n",
    "    thetas_batch[model], itr_numbers_batch, costs_batch = gradient_descent(dataset_train, target_train, thetas[model],  batch_size=len(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

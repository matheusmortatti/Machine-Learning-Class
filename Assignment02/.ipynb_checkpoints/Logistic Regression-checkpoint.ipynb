{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.datasets import load_digits\n",
    "import cmath as math\n",
    "import os\n",
    "import csv\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read training dataset\n",
    "# dataset_train = []\n",
    "# reader = csv.DictReader(open('fashion-mnist-dataset/fashion-mnist_train.csv', 'r'))\n",
    "# for line in reader:\n",
    "#      dataset_train.append(line)\n",
    "        \n",
    "# # Read test dataset\n",
    "# dataset_test = []\n",
    "# reader = csv.DictReader(open('fashion-mnist-dataset/fashion-mnist_test.csv', 'r'))\n",
    "# for line in reader:\n",
    "#      dataset_test.append(line)\n",
    "        \n",
    "# # Making a target dataset for each clothing option\n",
    "# # Finding out min and max values\n",
    "# min = 0\n",
    "# max = 0\n",
    "\n",
    "# for row in range(len(dataset_train)):\n",
    "#     if int(dataset_train[row][\"label\"]) < min:\n",
    "#         min = int(dataset_train[row][\"label\"])\n",
    "        \n",
    "#     if int(dataset_train[row][\"label\"]) > max:\n",
    "#         max = int(dataset_train[row][\"label\"])\n",
    "# size = max - min + 1\n",
    "\n",
    "# dataset_train_target = np.zeros((size, len(dataset_train)))\n",
    "\n",
    "# for row in range(len(dataset_train)):\n",
    "#     x = int(dataset_train[row][\"label\"])\n",
    "#     dataset_train_target[x][row] = 1\n",
    "\n",
    "\n",
    "    \n",
    "# # Read and treat training dataset\n",
    "# dataset_train = pandas.read_csv('fashion-mnist-dataset/fashion-mnist_train.csv').values #np.genfromtxt('fashion-mnist-dataset/fashion-mnist_train.csv', delimiter=',')\n",
    "# y_true = dataset_train[:,0]\n",
    "# dataset_train = np.delete(dataset_train, 0, 1).T\n",
    "# dataset_train = dataset_train / dataset_train.max()\n",
    "\n",
    "# # Read and treat test dataset\n",
    "# dataset_test = pandas.read_csv('fashion-mnist-dataset/fashion-mnist_test.csv').values\n",
    "# target_test = dataset_test[:,0]\n",
    "# dataset_test = np.delete(dataset_test, 0, 1).T\n",
    "# dataset_test = dataset_test / dataset_test.max()\n",
    "\n",
    "dataset_train, y_true = load_digits(10, True)\n",
    "dataset_train = np.transpose(dataset_train)\n",
    "\n",
    "half = len(y_true)//2\n",
    "\n",
    "data_train = dataset_train[:,:half]\n",
    "target_train = y_true[:half]\n",
    "data_val = dataset_train[:,half:]\n",
    "target_val = y_true[half:]\n",
    "\n",
    "\n",
    "dataset_train_target = np.zeros((10, data_train.shape[1]))\n",
    "\n",
    "for col in range(data_train.shape[1]):\n",
    "    dataset_train_target[target_train[col],col] = 1\n",
    "    \n",
    "dataset_val_target = np.zeros((10, data_val.shape[1]))\n",
    "\n",
    "for col in range(data_val.shape[1]):\n",
    "    dataset_val_target[target_val[col],col] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_thetas(data, size):\n",
    "    if len(data) == 0:\n",
    "        return []\n",
    "    thetas = np.zeros((size, len(data[0])))\n",
    "    return thetas\n",
    "\n",
    "def sigmoid(val):\n",
    "    return 1 / (1 + math.exp(-val))\n",
    "\n",
    "def calculate_hfunction(features, thetas):\n",
    "    h = sigmoid(np.matmul(thetas.T, features))\n",
    "    return h\n",
    "\n",
    "def calculate_cost_function(thetas, data, target):\n",
    "    m = len(data)\n",
    "\n",
    "    res = np.matmul(data.T, thetas)\n",
    "    \n",
    "    s = np.sum((res-target)*(res-target))\n",
    "    \n",
    "    return (1/(2*m)) * (s)\n",
    "\n",
    "def get_predictions(data, thetas):\n",
    "    res = []\n",
    "    for row in range(len(data)):\n",
    "        z = np.matmul([data[row]],np.column_stack([thetas]))\n",
    "        h = sigmoid(z)\n",
    "        res.append(h[0,0])\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#    GRADIENT DESCENT ALGORITHM     #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "\n",
    "def gradient_descent(data, target, thetas, batch_size = 1, max_iterations = 1000, stopCondition = 1e-04, learningRate = 0.01, j_step=1000):\n",
    "    done       = False\n",
    "    m          = len(data)\n",
    "    iterations = 0\n",
    "    \n",
    "    # After j_step iterations, compute cost function\n",
    "    costs       = []\n",
    "    itr_numbers = []\n",
    "    \n",
    "    retryCount = 0\n",
    "    retryMax = 1000\n",
    "\n",
    "    #startTime = current_time()\n",
    "    nrow = data.shape[0]\n",
    "    ncol = data.shape[1]\n",
    "    \n",
    "    while(iterations < max_iterations and not done):\n",
    "        # Step through the dataset in chuncks\n",
    "        for col in range(0, ncol, batch_size):\n",
    "            new_thetas = thetas.copy()\n",
    "\n",
    "            s = np.zeros((nrow))\n",
    "            # We add every row of the dataset to the error calculation (Batch)\n",
    "            for offset in range(batch_size):\n",
    "                if col + offset >= m:\n",
    "                    break\n",
    "                \n",
    "                sample = data[:,offset + col]\n",
    "                starget = target[offset + col]\n",
    "\n",
    "                h = calculate_hfunction(sample, thetas)\n",
    "                s = s + (h - starget) * sample\n",
    "\n",
    "            # Updating the new thetas vector values\n",
    "            new_thetas = thetas - ((learningRate / batch_size) * s)\n",
    "            \n",
    "            # keep a new cost value\n",
    "            if iterations % j_step == 0:\n",
    "                cost = calculate_cost_function(thetas, data, target)\n",
    "                if len(costs)>0 and cost > costs[-1]:\n",
    "                    learningRate /= 1.001\n",
    "                    if retryCount < retryMax:\n",
    "                        retryCount += 1\n",
    "                    else:\n",
    "                        iterations = max_iterations\n",
    "                else:\n",
    "                    retryCount = 0\n",
    "                costs.append(cost)\n",
    "                itr_numbers.append(iterations)\n",
    "                \n",
    "            iterations = iterations + 1\n",
    "            if iterations >= max_iterations:\n",
    "                break\n",
    "\n",
    "            # Atualization of the values of the thetas\n",
    "            thetas = new_thetas.copy()\n",
    "    \n",
    "    if iterations >= max_iterations:\n",
    "        print(\"Stopped by number of iterations\\n\")\n",
    "    if done:\n",
    "        print(\"Stopped by convergence\\n\")\n",
    "        \n",
    "    #endTime = current_time()\n",
    "    #print(\"RunTime = \", (endTime - startTime)/1000, \" seconds\")\n",
    "    \n",
    "    return thetas, itr_numbers, costs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by number of iterations\n",
      "\n",
      "Stopped by number of iterations\n",
      "\n",
      "Stopped by number of iterations\n",
      "\n",
      "Stopped by number of iterations\n",
      "\n",
      "Stopped by number of iterations\n",
      "\n",
      "Stopped by number of iterations\n",
      "\n",
      "Stopped by number of iterations\n",
      "\n",
      "Stopped by number of iterations\n",
      "\n",
      "Stopped by number of iterations\n",
      "\n",
      "Stopped by number of iterations\n",
      "\n",
      "0.9254727474972191\n",
      "0.7819799777530589\n",
      "0.864293659621802\n",
      "0.45161290322580644\n",
      "0.9221357063403782\n",
      "0.9110122358175751\n",
      "0.8164627363737486\n",
      "0.8186874304783093\n",
      "0.8476084538375973\n",
      "0.7864293659621802\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#                                   #\n",
    "#     BATCH GRADIENT ALGORITHM      #\n",
    "#                                   #\n",
    "#####################################\n",
    "\n",
    "thetas_batch = []\n",
    "\n",
    "\n",
    "for model in range (10):\n",
    "    target_train = dataset_train_target[model,:]\n",
    "    max_iter = 100\n",
    "    \n",
    "    thetas = np.ones((dataset_train.shape[0]))\n",
    "    thetas_batch.append(np.zeros((dataset_train.shape[0])))\n",
    "    thetas_batch[model], itr_numbers_batch, costs_batch = gradient_descent(data_train, target_train, thetas,  batch_size=1)\n",
    "\n",
    "for i in range(10):\n",
    "    t = thetas_batch[i]\n",
    "    m = dataset_val_target[i,:]\n",
    "\n",
    "    sig = np.vectorize(sigmoid)\n",
    "    cl = np.vectorize(lambda x: 1 if x.real > 0.5 else 0)\n",
    "    acc = 0\n",
    "    res = cl(sig(np.matmul(data_val.T, t)))\n",
    "\n",
    "    for k in range(res.shape[0]):\n",
    "        if m[k] == res[k]:\n",
    "            acc+=1\n",
    "    print(acc / res.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
